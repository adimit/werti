#
# fist real test grammar for gerund detection
#
# ATTENTION: uses Linigpipe interpretatiom of Brown/Penn Tagset
#
# ATTENTION: sets and templates with underscores are meant to be used 
# globally in the entire section they are specified in.
#

############################################################################# 
#
# Common definitions
#
############################################################################# 

#----- HANDLING PUNCTUATION PROPERLY ----------------------------------------

# TODO: abbreviations are broken.

DELIMITERS = "<.>" "<!>" "<?>" ; # sentence window

#----- LEXICAL BITS AND PIECES ----------------------------------------------

# misc
TEMPLATE _LEX_PHRASES = 
	(-3 ("<in>"ir) LINK +1 ("<spite>") LINK +1 ("<of>"))
	OR
	(-2 ("<instead>"ir) LINK +1 ("<of>"))
	OR
	(-1 ("<on>"ir))
	OR
	(-1 ("<after>"ir))
;

# verbs
LIST _LEX_ALWAYS_GERUND = 
   "<admit(s|ted)?>"r
   "<appreciat(s|ed)?>"r
   "<avoid(s|ed)?>"r
   "<celebrate(s|d)?>"r
   "<consider(s|ed)?>"r
   "<contemplate(s|d)?>"r
   "<defer(s|red)?>"r
   "<delay(s|ed)?>"r
   "<den(y|ies|ied)>"r
   "<detest(s|ed)?>"r
   "<discontinue(s|d)?>"r
   "<discuss(es|ed)?>"r
   "<dislike(s|d)?>"r
   "<dispute(s|d)?>"r
   "<endure(s|d)?>"r
   "<enjoy(s|ed)?>"r
   "<entail(s|ed)?>"r
   "<espace(s|d)?>"r
   "<excuse(s|d)?>"r
   "<explain(s|ed)?>"r
   "<fanc(y|ies|ied)>"r
   "<finish(s|ed)?>"r
   "<forgive(s)?>"r   "<forgave>"
   "<hinder(s|ed)?>"r
   "<imagine(s|d)?>"r
   "<involve(s|d)?>"r
   "<keep(s)?>"r   "<kept>"
   "<loathe(s|d)?>"r
   "<mention(s|ed)?>"r
   "<mind(s|d)?>"r
   "<miss(ed|es)?>"r
   "<pardon(s|ed)?>"r
   "<postpone(s|ed)?>"r
   "<practice(s|d)?>"r
   "<prevent(s|ed)?>"r
   "<quit(s)?>"r
   "<recall(s|ed)?>"r
   "<report(s|ed)?>"r
   "<resent(s|ed)?>"r
   "<resist(s|ed)?>"r
   "<risk(s|ed)?>"r
   "<suggest(s|ed)?>"r
   "<understand(s)?>"r   "<understood>"
;

LIST _LEX_GERUND_OR_TOINF_MEANING_CHANGE = 
   "<forget(s)?>"r   "<forgot>"
   "<help(s|ed)?>"r 
   "<need(s|ed)?>"r 
   "<regret(s|ed)?>"r
   "<remember(s|ed)?>"r
   "<stop(s|ped)?>"r 
   "<try>"   "<tries>"   "<tried>"
;


LIST _LEX_GERUND_OR_TOINF_NO_MEANING_CHANGE = 
   "<begin(s)?>"   "<began>"
   "<continue(s|ed)?>"r
   "<hate(s|d)?>"r
   "<like(s|d)?>"r
   "<love(s|ed)?>"r 
   "<prefer(s|red)?>"r
   "<start(s|ed)?>"r
   "<intend(s|ed)?>"r 
;


LIST _LEX_ALWAYS_TOINF = 
   "<agree(s|d)?>"r
   "<appear(s|ed)?>"r
   "<ask(s|ed)?>"r
   "<decide(s|d)?>"r
   "<expect(s|ed)?>"r
   "<hope(s|d)?>"r
   "<need(s|ed)?>"r
   "<offer(s|ed)?>"r
   "<plan(s|ned)?>"r
   "<pretend(s|ed)?>"r
   "<promise(s|d)?>"r
   "<refuse(s|d)?>"r
   "<seem(s|ed)?>"r
   "<want(s|ed)?>"r
;

SET _LEX_GERUND_OR_TOINF = _LEX_GERUND_OR_TOINF_MEANING_CHANGE OR _LEX_GERUND_OR_TOINF_NO_MEANING_CHANGE;

SET _LEX_GERUND_CANDIDATES = _LEX_GERUND_OR_TOINF OR _LEX_ALWAYS_GERUND;


#----- GLOBAL ABSTRACT SETS OF POS ------------------------------------------

LIST _INGFORM = VBG HVG BEG ; # gerunds or present participle
LIST _INFIN = BE-INF DO-INF HV-INF VB-INF; # to-infinitives (introduced below)
LIST _UNINF = BE DO GV VB;           # uninflected (infinitives or imperatives without to)
LIST _ADVER = RB RBR RBT; 	#  some types of adverbs used with infinitives
LIST _NEG   = "<not>" "<Not>";  # negation words, TODO: contractions?!
LIST _ADJEC = JJ JJT JJS JJR;
LIST _NOUNS = NN NN$ NNS NNS$ NP NP$ NPS NPS$;
LIST _ANYVERB_ANYFORM = VB VBD VBG VBN VBZ BE BED BEDZ BEG BEM BEN BER BEZ DO DOD DOZ HV HVD HVG HVN HVZ MD BE-INF DO-INF HV-INF VB-INF;




############################################################################# 
#
# Preprocessing: fixing tagger issues and introducing ambiguous readings
#
############################################################################# 

BEFORE-SECTIONS

# repair mistagged "to" before two or more adverbs 
"<To>" SUBSTITUTE (IN) (TO) (IN) ( +1*C _UNINF BARRIER (*) - _ADVER );
"<to>" SUBSTITUTE (IN) (TO) (IN) ( +1*C _UNINF BARRIER (*) - _ADVER );

# Introduce a new tag for double quotes. The tagset is missing this one. As the
# tagger does not know them, it produces all kinds of funny analyses instead.
APPEND ("" QUOT) ("<">");
APPEND ("" QUOT) ("<&quot;>");
SELECT (QUOT) (0 (QUOT));

# Simple sentence-initial question forms may have been assigned any
# funny tag.
APPEND ("" BEDZ) ("<Was>") (+1 (PPSS));
APPEND ("" BED)  ("<Were>")(+1 (PPSS));
APPEND ("" BEDZ) ("<was>") (+1 (PPSS));
APPEND ("" BED) ("<was>") (+1 (PPSS));

# 's contraction is always BEZ if not genitive 's
LIST GENITIVE  = NN$ DT$ CD$ AP$ RB$ PN$ NR$ NPS$ NP$ NNS$ JJ$;
APPEND ("" BEZ) ("<s>") (-1 ("<'>")) (NOT 0  GENITIVE);

# introduce infinitive tags (Brown tagset only knows "uninflected forms")
SUBSTITUTE (BE) (BE-INF) (BE) (-1*C (TO) BARRIER (*) - _ADVER);
SUBSTITUTE (DO) (DO-INF) (DO) (-1*C (TO) BARRIER (*) - _ADVER);
SUBSTITUTE (HV) (HV-INF) (HV) (-1*C (TO) BARRIER (*) - _ADVER);
SUBSTITUTE (VB) (VB-INF) (VB) (-1*C (TO) BARRIER (*) - _ADVER);

# add readings for all -ing forms (this should be done in a smarter way)
# 
SUBSTITUTE ("" VBG) ("---remove---" VBG) (VBG);
APPEND ("" VBG GERU)   (VBG);
APPEND ("" HVG GERU)   (HVG);
APPEND ("" BEG GERU)   (BEG);
APPEND ("" VBG PROG)   (VBG);
APPEND ("" HVG PROG)   (HVG);
APPEND ("" BEG PROG)   (BEG);
APPEND ("" VBG PART)   (VBG);
APPEND ("" HVG PART)   (HVG);
APPEND ("" BEG PART)   (BEG);
# remove readings without  tags.
LIST X = GERU PROG PART;
REMOVE ("---remove---" VBG);

# add reading for going-to-future
"<going>" APPEND ("" VGB GOFU) (VBG);

# add reading for going-to-future in the past
"<going>" APPEND ("" VGB GOFUPA) (VBG);

# some rare special cases:
# gerund-noun ("fishing-pole") seems to be noun compound, the gerund is
# assumed to be lexicalized.
APPEND ("" NN GLEX) _INGFORM (+1 ("<->")) (+2 _NOUNS);
APPEND ("" NN GLEX) _INGFORM (-1 ("<->")) (-2 _NOUNS);
SELECT (NN GLEX);
# same for adjective compounds ("good-looking")
APPEND ("" JJ GLEX) _INGFORM (+1 ("<->")) (+2 _ADJEC);
APPEND ("" JJ GLEX) _INGFORM (-1 ("<->")) (-2 _ADJEC);
SELECT (JJ GLEX);


############################################################################# 
#
# Rules: disambiguating -ing forms
#
############################################################################# 

SECTION

#----- UTILITY TEMPLATES AND LISTS/SETS -------------------------------------

# finite forms of to be, not including imperative
LIST _BE_FINITE = BEM BEZ BER BEN BED BEDZ;

# determiners and pronouns used in NPs
LIST _NP_DETPRON = DT DTS DTI AT PP$ PP$$ PPL PPLS PPO PPS PPSS;

# these are used as clause delimiters
LIST _COMMA  = "<,>" "<;>";
SET _COMMA_OR_SUBORD = _COMMA OR (CS); 



#----- GOING-TO FUTURE AND FUTURE-IN-THE-PAST -------------------------------

# forms of "to be" used in going-to future (in-the-past)
LIST GOFU_BE = BER BEM BEZ;
LIST GOFUPA_BE = BED BEDZ;

# simple going-to-future
# sentences
SELECT (GOFU) (-1* GOFU_BE BARRIER (*) - _NEG - _ADVER) (+1 (TO)) (+2 _INFIN);
# qestions
SELECT (GOFU) (-1* GOFU_BE BARRIER _ANYVERB_ANYFORM) (+1 (TO)) (+2 _INFIN) (+3* ("<?>"));

# going-to-future in the past
SELECT (GOFUPA) (-1*  GOFUPA_BE  BARRIER (*) - _NEG - _ADVER) (+1 (TO)) (+2 _INFIN);
# question
SELECT (GOFUPA) (-1*  GOFUPA_BE BARRIER _ANYVERB_ANYFORM) (+1 (TO)) (+2 _INFIN) (+3* ("<?>"));


#----- OTHER PROGRESSIVE FORM READINGS --------------------------------------

# sentence
SELECT (PROG) (-1* _BE_FINITE BARRIER (*) - _NEG - _ADVER);
# question
SELECT (PROG) (-1* _BE_FINITE BARRIER _ANYVERB_ANYFORM) (+1* ("<?>"));

#----- PARTICIPLE READINGS --------------------------------------------------

# "... the (not) very brightly shining gem ..."
SELECT (PART) (-1* _NP_DETPRON BARRIER (*) - _ADVER - _NEG - (QL)) (+1 _NOUNS);

# "... you racing ..."
# "... of him having stolen ..."
# "... herself wondering how ..."
SELECT (PART) (-1 (PPO));
SELECT (PART) (-1 (PPL));

# Participle + Noun Phrase or Prepositional Phrase at the sentence beginning.
# TODO: does this quite sledgehammery rule overgenerate??
SELECT (PART) (-1 (>>>)) (+1*  _COMMA_OR_SUBORD BARRIER _ANYVERB_ANYFORM );

# parenthesis
# "... , Peter talking loudly to the mirror, ..."
# TODO: this does overgenerate!
SELECT (PART) (-1* _COMMA BARRIER _ANYVERB_ANYFORM ) (+1*  _COMMA_OR_SUBORD BARRIER _ANYVERB_ANYFORM );

# "..., not noticing that..."
# TODO: this does overgenerate!
SELECT (PART) (-1* _COMMA BARRIER _ANYVERB_ANYFORM ) (NOT -1* (IN) BARRIER_COMMA ) ((+1* _COMMA_OR_SUBORD BARRIER _ANYVERB_ANYFORM ) OR (+1* (<<<) BARRIER _ANYVERB_ANYFORM)) ;


#----- GERUND READINGS ------------------------------------------------------

### treat lexical sure-fire verbs

# without subject
SELECT (GERU) (-1 _LEX_GERUND_CANDIDATES LINK 0 _ANYVERB_ANYFORM );

# and with a subject 
# TODO: does this overgenerate?
SELECT (GERU) (-1 _NOUNS LINK -1 _LEX_GERUND_CANDIDATES LINK 0 _ANYVERB_ANYFORM );
SELECT (GERU) (-1 (PPO) LINK -1 _LEX_GERUND_CANDIDATES LINK 0 _ANYVERB_ANYFORM );
SELECT (GERU) (-1 (PP$) LINK -1 _LEX_GERUND_CANDIDATES LINK 0 _ANYVERB_ANYFORM );

### lexical sure-fire phrases
SELECT (GERU) (T:_LEX_PHRASES);

### treat the rest

# simple rules that should be not too dangerous, obtained from simple corpus
# observations
SELECT (GERU) (-2 _ADVER) (-1 (IN));
SELECT (GERU) (-2 _ADVER) (-1 (CS));
SELECT (GERU) (-2 _ADJEC) (-1 (IN));
SELECT (GERU) (-2 _ADJEC) (-1 (CS));

# PP object of a noun 
# "... plan for getting out ..."
# "... of his (not) really having stolen ..."
SELECT (GERU) (-1* _NOUNS BARRIER (*) - _ADVER - _NEG - (QL) LINK  -1 (IN));

# "... your (terrible) racing ..."
SELECT (GERU) (-1* (PP$) BARRIER (*) - _ADJEC - (QL) );


# very simple sleghemmer rules that catch most cases.
# TODO: this overgenerates too much
#SELECT (GERU) (-1 (IN));
#SELECT (GERU) (-1 (CS));

# gerund (with own arguments) as subject argument to the verb in 3rd person
# and/or past tense or will-future (with optional adverbs)
# "... playing playfully is awesome ... "
# "... playing the guitar was what he did ... "
LIST _3P_PRES = VBZ BEZ DOZ VHZ;
LIST _3P_PAST = BEDZ DOD HVD VBD;
SELECT (GERU) ( +1* _3P_PRES BARRIER _COMMA_OR_SUBORD OR _ANYVERB_ANYFORM);
SELECT (GERU) ( +1* _3P_PAST BARRIER _COMMA_OR_SUBORD OR _ANYVERB_ANYFORM);
SELECT (GERU) ( +1* (MD) BARRIER _COMMA_OR_SUBORD OR _ANYVERB_ANYFORM LINK +1 _UNINF);

# gerund as the object of a preposition
# "He insisted on telling us the truth."
# "He prevented the sun from shining."
SELECT (GERU) (-1 (IN)) (-2*  _ANYVERB_ANYFORM BARRIER _COMMA);

# 'predicative gerund' such as "Being very good (is incredibly bad.)"
SELECT (GERU) (0 (BEG)) (+1* _ADVER BARRIER (*) - (QL) );




############################################################################# 
#
# After inferring the required information: marking of the chunks
#
############################################################################# 

AFTER-SECTIONS

# ATTENTION: since we do not want ambigous annotations to be marked,
# every constraint here must be careful (marked with C). This will
# ommit ambigous readings.

# marking infinitive constructions: TO ADVER* INFIN
# INF-B: beginning of chunk. INF-I: inside of chunk.
ADD (INF-B) (TO)    (+*1C _INFIN BARRIER (*) - _ADVER ); 
ADD (INF-I) _INFIN (-*1C (TO) BARRIER (*) - _ADVER );
ADD (INF-I) _ADVER (-*1C (TO) BARRIER (*) - _ADVER ) (+*1C _INFIN BARRIER (*) - _ADVER );

# marking gerund constructions
ADD (GER-B) (GERU) (0C (GERU));

# these are used for the debug option of showing all known ingforms
ADD (GOI-B) (GOFU) (0C (GOFU));
ADD (GOP-B) (GOFUPA) (0C (GOFUPA));
ADD (PRO-B) (PROG) (0C (PROG));
ADD (PAR-B) (PART) (0C (PART));

# and this marks the ones which are still ambiguous, ...
APPEND ("" AMB-B) (GERU) (NOT 0 (GER-B));
APPEND ("" AMB-B) (PROG) (NOT 0 (PRO-B)) (NOT 0 (AMB-B));
APPEND ("" AMB-B) (PART) (NOT 0 (PAR-B)) (NOT 0 (AMB-B));
APPEND ("" AMB-B) (GOFU) (NOT 0 (GOI-B)) (NOT 0 (AMB-B));
APPEND ("" AMB-B) (GOFUPA) (NOT 0 (GOP-B))  (NOT 0 (AMB-B));
# ... and then delete the rest (better comment out this during grammar development!)
SELECT  (AMB-B) (0 (AMB-B));



############################################################################# 
#
# Finding clue phrases and annotating them as chunks.
#
############################################################################# 

AFTER-SECTIONS

# these are the begin-tags of all types of clues there are
LIST _ALLCUETYPES_B = CLU-GERONLY-B  CLU-INFONLY-B CLU-BOTHMEANDIFF-B CLU-BOTHMEANSAME-B;

# TODO: lexical phrase clues 
# this is tricky because they currently are TEMPLATEs.

# marking up lexical clues
# those with gerunds...
ADD (CLU-GERONLY-B) _LEX_ALWAYS_GERUND (+1* (GER-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );
ADD (CLU-BOTHMEANDIFF-B) _LEX_GERUND_OR_TOINF_MEANING_CHANGE  (+1* (GER-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );
ADD (CLU-BOTHMEANSAME-B) _LEX_GERUND_OR_TOINF_NO_MEANING_CHANGE  (+1* (GER-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );
# ... and those with infinitives
ADD (CLU-INFONLY-B)  _LEX_ALWAYS_TOINF (+1* (INF-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );
ADD (CLU-BOTHMEANDIFF-B)  _LEX_GERUND_OR_TOINF_MEANING_CHANGE (+1* (INF-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );
ADD (CLU-BOTHMEANSAME-B)  _LEX_GERUND_OR_TOINF_NO_MEANING_CHANGE (+1* (INF-B) BARRIER  _ANYVERB_ANYFORM OR _COMMA ) (0 _ANYVERB_ANYFORM );


# marking up all gerunds preceding prepositions 
# TODO: is this what the learner wants to see?
ADD (CLU-GERONLY-B) (IN) (+1C (GER-B));

############################################################################# 
#
# Marking relevant text strands that include a clue phrase + gerund or inf
# as RELEVANT chunks.
#
############################################################################# 

AFTER-SECTIONS

### ad marker for relevant text spans including clue phrases and gerunds
ADD (RELEVANT-B) ("") (0C _ALLCUETYPES_B) (+1*C (GER-B));
ADD (RELEVANT-I) ("") (-1*C (RELEVANT-B)) (+1*C (GER-B));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-I)) (0C (GER-B));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-B)) (0C (GER-B));

### ad marker for relevant text spans including clue phrases and infinitives
ADD (RELEVANT-B) ("") (0C _ALLCUETYPES_B) (+1*C (INF-B));
ADD (RELEVANT-I) ("") (-1*C (RELEVANT-B)) (+1*C (INF-B));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-I)) (0C (INF-B));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-B)) (0C (INF-B));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-I)) (0C (INF-I));
ADD (RELEVANT-I) ("") (-1 (RELEVANT-B)) (0C (INF-I));

